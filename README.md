# Pull, OtimizaÃ§Ã£o e AvaliaÃ§Ã£o de Prompts com LangChain e LangSmith

## Objetivo

Software capaz de:

1. **Fazer pull de prompts** do LangSmith Prompt Hub contendo prompts de baixa qualidade
2. **Refatorar e otimizar** esses prompts usando tÃ©cnicas avanÃ§adas de Prompt Engineering
3. **Fazer push dos prompts otimizados** de volta ao LangSmith
4. **Avaliar a qualidade** atravÃ©s de mÃ©tricas customizadas (Tone, Acceptance Criteria, Format, Completeness)
5. **Atingir pontuaÃ§Ã£o mÃ­nima** de 0.9 (90%) em todas as mÃ©tricas de avaliaÃ§Ã£o

---

## TÃ©cnicas Aplicadas (Fase 2)

### 1. Role Prompting
**O que Ã©:** Definir uma persona especÃ­fica com expertise relevante para o modelo assumir.

**Por que escolhi:** Um Product Manager SÃªnior com experiÃªncia em metodologias Ã¡geis Ã© a persona ideal para transformar bug reports em User Stories de qualidade. A definiÃ§Ã£o de persona melhora drasticamente a qualidade, tom e profissionalismo das respostas.

**Como apliquei:**
```
VocÃª Ã© um Product Manager SÃªnior com mais de 10 anos de experiÃªncia
em desenvolvimento Ã¡gil de software. VocÃª Ã© especialista em transformar
relatos tÃ©cnicos de bugs em User Stories claras, completas e acionÃ¡veis.
```

### 2. Few-shot Learning
**O que Ã©:** Fornecer exemplos concretos de entrada/saÃ­da para o modelo aprender o padrÃ£o esperado.

**Por que escolhi:** Exemplos concretos sÃ£o a forma mais eficaz de comunicar ao modelo exatamente o formato, nÃ­vel de detalhe e qualidade esperados. IncluÃ­ 3 exemplos cobrindo diferentes complexidades (simples, mÃ©dio, complexo).

**Como apliquei:**
- **Exemplo 1 (Simples):** Bug de botÃ£o de carrinho -> User Story com 5 critÃ©rios de aceitaÃ§Ã£o
- **Exemplo 2 (MÃ©dio):** Bug de performance de relatÃ³rio -> User Story com critÃ©rios + contexto tÃ©cnico
- **Exemplo 3 (Complexo):** Bug de checkout com 4 problemas -> User Story com seÃ§Ãµes organizadas, contexto e tasks

### 3. Chain of Thought (CoT)
**O que Ã©:** Instruir o modelo a raciocinar passo a passo antes de gerar a resposta final.

**Por que escolhi:** A transformaÃ§Ã£o de bug em User Story exige anÃ¡lise cuidadosa de quem Ã© o usuÃ¡rio, qual o valor de negÃ³cio, e quais critÃ©rios sÃ£o relevantes. O CoT orienta o modelo a seguir um processo mental estruturado.

**Como apliquei:**
```
Ao receber um bug report, siga estes passos mentalmente:
1. Identifique a complexidade (simples, mÃ©dio, complexo)
2. Identifique o usuÃ¡rio afetado
3. Identifique o valor de negÃ³cio
4. Extraia critÃ©rios de aceitaÃ§Ã£o
5. Verifique completude
```

### 4. Skeleton of Thought
**O que Ã©:** Definir uma estrutura/esqueleto obrigatÃ³rio para a resposta.

**Por que escolhi:** Garante consistÃªncia no formato de saÃ­da, independentemente da complexidade do bug. O esqueleto define seÃ§Ãµes obrigatÃ³rias (User Story, CritÃ©rios de AceitaÃ§Ã£o) e opcionais baseadas na complexidade (Contexto TÃ©cnico, Tasks).

**Como apliquei:**
```
## User Story
**Como um** [persona], **eu quero** [aÃ§Ã£o], **para que** [benefÃ­cio].

## CritÃ©rios de AceitaÃ§Ã£o (Given-When-Then)
## Contexto TÃ©cnico (para bugs mÃ©dios/complexos)
## Tasks TÃ©cnicas Sugeridas (para bugs complexos)
```

---

## Resultados Finais

### Links PÃºblicos do LangSmith

- **Dashboard do Projeto (avaliaÃ§Ãµes):** [https://smith.langchain.com/o/ee0f8b68-bd97-4ccd-9a82-8ef266fee4f5/projects/p/405307ca-9589-4f32-aafe-d8c06b39d2e4](https://smith.langchain.com/o/ee0f8b68-bd97-4ccd-9a82-8ef266fee4f5/projects/p/405307ca-9589-4f32-aafe-d8c06b39d2e4)
- **Prompt Otimizado no Hub:** [https://smith.langchain.com/hub/vinicius-vieira/bug_to_user_story_v2](https://smith.langchain.com/hub/vinicius-vieira/bug_to_user_story_v2)

### Screenshots

![Resultado da AvaliaÃ§Ã£o - screenshot:1](screenshot1.png)
![Resultado da AvaliaÃ§Ã£o - screenshot:2](screenshot2.png)
![Resultado da AvaliaÃ§Ã£o - screenshot:3](screenshot3.png)
![Resultado da AvaliaÃ§Ã£o - screenshot:4](screenshot4.png)

![Resultado da AvaliaÃ§Ã£o - screenshot:5](screenshot5.png)

### Log do processamento

```
==================================================
AVALIAÃ‡ÃƒO DE PROMPTS OTIMIZADOS
==================================================

Provider: openai
Modelo Principal: gpt-5-mini
Modelo de AvaliaÃ§Ã£o: gpt-5-mini

Criando dataset de avaliaÃ§Ã£o: prompt-optimization-challenge-resolved-eval...
   âœ“ Carregados 15 exemplos do arquivo datasets/bug_to_user_story.jsonl
   âœ“ Dataset 'prompt-optimization-challenge-resolved-eval' jÃ¡ existe, usando existente

ðŸ” Avaliando: bug_to_user_story_v2
   Puxando prompt do LangSmith Hub: bug_to_user_story_v2
   âœ“ Prompt carregado com sucesso
   Dataset: 15 exemplos
   Avaliando exemplos com mÃ©tricas Bug-to-User-Story...
      [1/10] T:0.94 A:0.94 F:1.00 C:0.99
      [2/10] T:0.94 A:0.95 F:0.98 C:0.94
      [3/10] T:0.96 A:0.97 F:0.96 C:0.93
      [4/10] T:0.94 A:0.97 F:1.00 C:0.92
      [5/10] T:0.93 A:0.97 F:1.00 C:1.00
      [6/10] T:0.91 A:0.96 F:1.00 C:0.98
      [7/10] T:1.00 A:0.99 F:1.00 C:1.00
      [8/10] T:0.91 A:0.96 F:1.00 C:0.95
      [9/10] T:0.97 A:0.89 F:1.00 C:0.98
      [10/10] T:0.96 A:0.95 F:0.98 C:0.97

==================================================
Prompt: bug_to_user_story_v2
==================================================

MÃ©tricas Bug-to-User-Story:
  - Tone Score:                0.95 âœ“
  - Acceptance Criteria Score: 0.96 âœ“
  - User Story Format Score:   0.99 âœ“
  - Completeness Score:        0.97 âœ“

ðŸ“Š MÃ‰DIA GERAL: 0.9650

âœ… STATUS: APROVADO âœ“ - Todas as mÃ©tricas atingiram o mÃ­nimo de 0.9
```

### Tabela Comparativa: v1 vs v2

| MÃ©trica | Prompt v1 (Ruim) | Prompt v2 (Otimizado) | Meta |
|---------|------------------|-----------------------|------|
| Tone Score | ~0.4-0.5 | **0.95** âœ“ | >= 0.9 |
| Acceptance Criteria | ~0.3-0.5 | **0.97** âœ“ | >= 0.9 |
| User Story Format | ~0.4-0.5 | **0.99** âœ“ | >= 0.9 |
| Completeness | ~0.3-0.5 | **0.96** âœ“ | >= 0.9 |
| **MÃ‰DIA GERAL** | ~0.4 | **0.9692** âœ“ | >= 0.9 |

### Problemas do Prompt v1
- Sem definiÃ§Ã£o de persona (tom genÃ©rico)
- Sem exemplos (Few-shot ausente)
- Sem estrutura de saÃ­da definida
- InstruÃ§Ãµes vagas ("crie uma user story")
- Sem tratamento de edge cases ou bugs complexos

### Melhorias do Prompt v2
- Persona de PM SÃªnior com expertise em Ã¡gil
- 3 exemplos Few-shot (simples, mÃ©dio, complexo)
- Estrutura de saÃ­da obrigatÃ³ria em Markdown
- Processo de raciocÃ­nio Chain of Thought em 5 passos
- 8 regras explÃ­citas de qualidade
- Tratamento diferenciado por complexidade

---

## Como Executar

### PrÃ©-requisitos

- Python 3.9+
- Conta no LangSmith (https://smith.langchain.com)
- API Key do LangSmith
- API Key da OpenAI ou Google Gemini

### InstalaÃ§Ã£o

```bash
# 1. Clone o repositÃ³rio
git clone <URL_DO_REPO>
cd mba-ia-pull-evaluation-prompt

# 2. Crie e ative um ambiente virtual
python3 -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate

# 3. Instale as dependÃªncias
pip install -r requirements.txt

# 4. Configure as variÃ¡veis de ambiente
cp .env.example .env
# Edite o .env com suas credenciais
```

### ConfiguraÃ§Ã£o do .env

```env
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=sua_chave_aqui
LANGSMITH_PROJECT=prompt-optimization-challenge-resolved
USERNAME_LANGSMITH_HUB=seu_username_aqui

# Para Google Gemini (gratuito)
LLM_PROVIDER=google
LLM_MODEL=gemini-2.5-flash
EVAL_MODEL=gemini-2.5-flash
GOOGLE_API_KEY=sua_chave_aqui

# Ou para OpenAI
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# EVAL_MODEL=gpt-4o
# OPENAI_API_KEY=sua_chave_aqui
```

### ExecuÃ§Ã£o Passo a Passo

```bash
# Fase 1: Pull dos prompts iniciais (ruins)
python src/pull_prompts.py

# Fase 2: O prompt otimizado jÃ¡ estÃ¡ em prompts/bug_to_user_story_v2.yml

# Fase 3: Push do prompt otimizado
python src/push_prompts.py

# Fase 4: AvaliaÃ§Ã£o
python src/evaluate.py

# Testes de validaÃ§Ã£o
pytest tests/test_prompts.py -v
```

### CritÃ©rios de AprovaÃ§Ã£o

```
- Tone Score >= 0.9
- Acceptance Criteria Score >= 0.9
- User Story Format Score >= 0.9
- Completeness Score >= 0.9
- MÃ‰DIA das 4 mÃ©tricas >= 0.9
```

**IMPORTANTE:** TODAS as 4 mÃ©tricas devem estar >= 0.9, nÃ£o apenas a mÃ©dia!

---

## Estrutura do Projeto

```
mba-ia-pull-evaluation-prompt/
â”œâ”€â”€ .env.example              # Template das variÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt          # DependÃªncias Python
â”œâ”€â”€ README.md                 # DocumentaÃ§Ã£o do processo
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ bug_to_user_story_v1.yml       # Prompt inicial (baixa qualidade)
â”‚   â””â”€â”€ bug_to_user_story_v2.yml       # Prompt otimizado
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ bug_to_user_story.jsonl        # 15 exemplos de bugs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pull_prompts.py       # Pull do LangSmith Hub
â”‚   â”œâ”€â”€ push_prompts.py       # Push ao LangSmith Hub
â”‚   â”œâ”€â”€ evaluate.py           # AvaliaÃ§Ã£o automÃ¡tica com 4 mÃ©tricas
â”‚   â”œâ”€â”€ metrics.py            # 7 mÃ©tricas implementadas (3 gerais + 4 especÃ­ficas)
â”‚   â”œâ”€â”€ dataset.py            # Gerenciamento do dataset de bugs
â”‚   â””â”€â”€ utils.py              # FunÃ§Ãµes auxiliares
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_prompts.py       # 8 testes de validaÃ§Ã£o
```

## Tecnologias Utilizadas

- **Linguagem:** Python 3.9+
- **Framework:** LangChain
- **Plataforma de avaliaÃ§Ã£o:** LangSmith
- **GestÃ£o de prompts:** LangSmith Prompt Hub
- **Formato de prompts:** YAML
- **LLM:** Google Gemini (gemini-2.5-flash) ou OpenAI (gpt-4o-mini / gpt-4o)
- **Testes:** pytest
